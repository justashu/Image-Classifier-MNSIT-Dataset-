{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5cc39f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot\n",
    "from scipy import optimize\n",
    "from scipy.io import loadmat\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde0faa2",
   "metadata": {},
   "source": [
    "# 1. Inspect and plot some portion of the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "456603ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.read_csv(os.path.join('fashion-mnist_train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbd8e44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialise a dictionary and map the 'label' from the dataframe \n",
    "#to the specific kind of wearable it is.\n",
    "label_dict = {0:'T-Shirt/Top',1:'Trouser',2:'Pullover',3:'Dress',\n",
    "              4:'Coat',5:'Sandals',6:'Shirt',7:'Sneaker',8:'Bag',9:'Ankle boots'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acc5a9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Segregate the data, normalise the feature vector, initialise a dictionary corresponding to the output array and map it. \n",
    "#Print a subset of the data like we did for the hand-written digit classification\n",
    "def data_clean_Display(data): # 'data' is a pandas datafram                   \n",
    "        \n",
    "        y = data.label.values\n",
    "        X = data.drop('label', axis=1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        X = np.array(X)\n",
    "        X = (X - X.min(axis=1)[:,None])/((X.max(axis=1) - X.min(axis=1))[:,None])\n",
    "        #n = (n - n.min(axis=1)[:,None])/((n.max(axis=1) - n.min(axis=1))[:,None])\n",
    "        y = np.array(y)# numpy array\n",
    "    \n",
    "        \n",
    "        return X,y\n",
    "\n",
    "X_train,y_train = data_clean_Display(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ad2df23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.21960784 0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[1:10,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a36c91af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pullover       Ankle boots       Coat       "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Write code here to display sample set of data\n",
    "def displayData(X, example_width=None, figsize=(5, 5)):\n",
    "    \"\"\"\n",
    "    Displays 2D data stored in X in a nice grid.\n",
    "    \"\"\"\n",
    "    # Compute rows, cols\n",
    "    if X.ndim == 2:\n",
    "        m, n = X.shape\n",
    "    elif X.ndim == 1:\n",
    "        n = X.size\n",
    "        m = 1\n",
    "        X = X[None]  # Promote to a 2 dimensional array\n",
    "    else:\n",
    "        raise IndexError('Input X should be 1 or 2 dimensional.')\n",
    "\n",
    "    example_width = example_width or int(np.round(np.sqrt(n)))\n",
    "    example_height = n / example_width\n",
    "\n",
    "    # Compute number of items to display\n",
    "    display_rows = int(np.floor(np.sqrt(m)))\n",
    "    display_cols = int(np.ceil(m / display_rows))\n",
    "\n",
    "    fig, ax_array = pyplot.subplots(display_rows, display_cols, figsize=figsize)\n",
    "    fig.subplots_adjust(wspace=0.025, hspace=0.025)\n",
    "\n",
    "    ax_array = [ax_array] if m == 1 else ax_array.ravel()\n",
    "\n",
    "    for i, ax in enumerate(ax_array):\n",
    "        # Display Image\n",
    "        h = ax.imshow(X[i].reshape(example_width, example_width, order='F'),\n",
    "                      cmap='Greys', extent=[0, 1, 0, 1])\n",
    "        ax.axis('off')\n",
    "\n",
    "m = y_train.size\n",
    "\n",
    "rand_indices = np.random.choice(m, 3, replace=False)\n",
    "\n",
    "for l in rand_indices:\n",
    "   print(label_dict[y_train[l]], end='       ')\n",
    "sel = X_train[rand_indices, :]        \n",
    "\n",
    "\n",
    "displayData(sel)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a5061ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implement the sigmoid function\n",
    "def sigmoid(z):\n",
    "     \n",
    "    g = 1/(1 + np.exp(-z))\n",
    "        \n",
    "    return g\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38d3b915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction based on trained model\n",
    "# Use sigmoid function to calculate probability rounded off to either 0 or 1\n",
    "#Prediction function for single hidden layer.\n",
    "def predictSingleHiddenLayer(w1, w2, X): \n",
    "    \n",
    "    if X.ndim==1:\n",
    "        X=X[None]\n",
    "    \n",
    "    m=X.shape[0]\n",
    "    num_labels= w2.shape[0]\n",
    "    \n",
    "    p= np.zeros(m)\n",
    "    \n",
    "    a1= np.concatenate([np.ones((m,1)), X], axis=1) #Input layer\n",
    "    \n",
    "    a2= sigmoid(a1.dot(w1.T)) #Hidden Layer\n",
    "    \n",
    "    a2= np.concatenate([np.ones((a2.shape[0],1)), a2 ], axis=1) #Activation of 2nd layer\n",
    "    \n",
    "    a3= sigmoid(a2.dot(w2.T))\n",
    "    \n",
    "    p= np.argmax(a3, axis=1)     # 'p' should be a vector of size equal to that of vector 'y'\n",
    "        \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c25f7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction function for double hidden layer.\n",
    "def predictDoubleHiddenLayer(w1, w2, w3, X): \n",
    "    if X.ndim==1:\n",
    "        X=X[None]\n",
    "    \n",
    "    m=X.shape[0]\n",
    "    num_labels= w3.shape[0]\n",
    "    \n",
    "    p= np.zeros(m)\n",
    "    \n",
    "    a1= np.concatenate([np.ones((m,1)), X], axis=1) #Input layer\n",
    "    \n",
    "    a2= sigmoid(a1.dot(w1.T)) #Hidden Layer\n",
    "    \n",
    "    a2= np.concatenate([np.ones((a2.shape[0],1)), a2 ], axis=1) #Activation of 2nd layer\n",
    "    \n",
    "    a3= sigmoid(a2.dot(w2.T))\n",
    "    \n",
    "    a3= np.concatenate([np.ones((a3.shape[0],1)), a3 ], axis=1) #Activation of 3rd layer\n",
    "    \n",
    "    a4= sigmoid(a3.dot(w3.T))\n",
    "    \n",
    "    p= np.argmax(a4, axis=1)     # 'p' should be a vector of size equal to that of vector 'y'\n",
    "        \n",
    "\n",
    "        \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acd9fba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#implement the gradient of the sigmoid function\n",
    "def sigmoidGradient(z):\n",
    "    g = np.zeros(z.shape)\n",
    "    g = sigmoid(z)*(1-sigmoid(z))\n",
    "\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b15b6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the parameters you will use for this exercise\n",
    "input_layer_size  =  784\n",
    "hidden_layer_size_One = 40   \n",
    "hidden_layer_size_Two = 40  \n",
    "num_labels = 10          #number of output labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7992a8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomly initialise weights.\n",
    "def randInitializeWeights(L_in, L_out, epsilon_init=0.12):\n",
    "    W= np.zeros((L_out, L_in+1))\n",
    "    W= np.random.rand(L_out, L_in+1)*2*epsilon_init-epsilon_init\n",
    "    \n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a1e28b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for single hidden layer\n",
    "initial_w1_1 = randInitializeWeights(input_layer_size, hidden_layer_size_One)\n",
    "initial_w2_1 = randInitializeWeights(hidden_layer_size_One, num_labels)\n",
    "\n",
    "# for double hidden layer\n",
    "initial_w1_2 = randInitializeWeights(input_layer_size, hidden_layer_size_One)\n",
    "initial_w2_2 = randInitializeWeights(hidden_layer_size_One, hidden_layer_size_Two)\n",
    "initial_w3_2 = randInitializeWeights(hidden_layer_size_Two, num_labels)    #only when you're using the Second Hidden Layer\n",
    "\n",
    "#Unroll parameters into a single array\n",
    "initial_nn_params_1 = np.concatenate([initial_w1_1.ravel(), initial_w2_1.ravel()], axis=0)  # for single hidden layer\n",
    "initial_nn_params_2 = np.concatenate([initial_w1_2.ravel(), initial_w2_2.ravel(), initial_w3_2.ravel()], axis=0)  # for double hidden layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df40e071",
   "metadata": {},
   "source": [
    "# 2a.  for one hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a160f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for one hidden layer\n",
    "def nnCostFunction_1(nn_params,\n",
    "                   input_layer_size,\n",
    "                   hidden_layer_size_One,\n",
    "                   num_labels,\n",
    "                   X, y, lambda_=0.1):\n",
    "    \n",
    "    \n",
    "    # Reshape nn_params back into the parameters w1 and w2, the weight matrices\n",
    "    # for our 2 layer neural network\n",
    "    s1 = input_layer_size\n",
    "    s2 = hidden_layer_size_One\n",
    "    s3 = num_labels\n",
    "    \n",
    "    w1 = np.reshape(nn_params[:s2 * (s1 + 1)], (s2, (s1 + 1)))\n",
    "\n",
    "    w2 = np.reshape(nn_params[(s2 * (s1 + 1)):], (s3, (s2 + 1)))\n",
    "   \n",
    "    # Setup some useful variables\n",
    "    m = y.size\n",
    "         \n",
    "    # You need to return the following variables correctly \n",
    "    J = 0\n",
    "    w1_grad = np.zeros(w1.shape)\n",
    "    w2_grad = np.zeros(w2.shape)\n",
    "\n",
    "    # ================================================================================================\n",
    "    \n",
    "    a1 = np.concatenate([np.ones((m, 1)), X], axis=1)\n",
    "    \n",
    "    a2 = sigmoid(a1.dot(w1.T))\n",
    "    a2 = np.concatenate([np.ones((a2.shape[0], 1)), a2], axis=1)\n",
    "    \n",
    "    a3 = sigmoid(a2.dot(w2.T))\n",
    "    \n",
    "    y_matrix = y.reshape(-1)\n",
    "    y_matrix = np.eye(num_labels)[y_matrix]\n",
    "    \n",
    "    temp1 = w1\n",
    "    temp2 = w2\n",
    "    \n",
    "    # Add regularization term\n",
    "    \n",
    "    reg_term = (lambda_ / (2 * m)) * (np.sum(np.square(temp1[:, 1:])) + np.sum(np.square(temp2[:, 1:])))\n",
    "    \n",
    "    J = -(1 / m) * np.sum((np.log(a3) * y_matrix) + np.log(1 - a3) * (1 - y_matrix)) + reg_term\n",
    "  \n",
    "    # Backpropogation\n",
    "    delta_3= a3-y_matrix #Error of O/P layer\n",
    "    delta_2= delta_3.dot(w2)[:, 1:]*sigmoidGradient(a1.dot(w1.T)) #Error of hidden layer 1.\n",
    "    \n",
    "    Delta1= delta_2.T.dot(a1)\n",
    "    Delta2= delta_3.T.dot(a2)\n",
    "\n",
    "    \n",
    "    # Add regularization to gradient\n",
    "\n",
    "    \n",
    "    w1_grad= (1/m)*Delta1\n",
    "    w2_grad= (1/m)*Delta2\n",
    "    \n",
    "    w1_grad[:, 1:]=  w1_grad[:, 1:] + (lambda_/m)*w1[:, 1:]\n",
    "    w2_grad[:, 1:]=  w2_grad[:, 1:] + (lambda_/m)*w2[:, 1:]\n",
    "    \n",
    "    grad= np.concatenate([w1_grad.ravel(), w2_grad.ravel()]) \n",
    "    #=======================================================================================================\n",
    "   \n",
    "    \n",
    "    return J,grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9edf0e7",
   "metadata": {},
   "source": [
    "# 2b. for two hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7009004b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def nnCostFunction_2(nn_params,\n",
    "                   input_layer_size,\n",
    "                   hidden_layer_size_One,\n",
    "                   hidden_layer_size_Two,\n",
    "                   num_labels,\n",
    "                   X, y, lambda_=0.1):\n",
    "    \n",
    "    \n",
    "    # Reshape nn_params back into the parameters w1 ,w2 and w3, the weight matrices\n",
    "    s1 = input_layer_size\n",
    "    s2 = hidden_layer_size_One\n",
    "    s3 = hidden_layer_size_Two\n",
    "    s4 = num_labels\n",
    "    \n",
    "    w1 = np.reshape(nn_params[:s2 * (s1 + 1)], (s2, (s1 + 1)))\n",
    "\n",
    "    w2 = np.reshape(nn_params[(s2 * (s1 + 1)):s2 * (s1 + 1)+(s3 * (s2 + 1))], (s3, (s2 + 1)))\n",
    "    w3 = np.reshape(nn_params[(s2 * (s1 + 1)+(s3 * (s2 + 1))):], (s4, (s3 + 1)))\n",
    "    # Setup some useful variables\n",
    "    m = y.size\n",
    "         \n",
    "    # You need to return the following variables correctly \n",
    "    J = 0\n",
    "    w1_grad = np.zeros(w1.shape)\n",
    "    w2_grad = np.zeros(w2.shape)\n",
    "    w3_grad = np.zeros(w3.shape)\n",
    "\n",
    "    # ================================================================================================\n",
    "    \n",
    "    a1 = np.concatenate([np.ones((m, 1)), X], axis=1)\n",
    "    \n",
    "    a2 = sigmoid(a1.dot(w1.T))\n",
    "    a2 = np.concatenate([np.ones((a2.shape[0], 1)), a2], axis=1)\n",
    "    \n",
    "    a3 = sigmoid(a2.dot(w2.T))\n",
    "    a3 = np.concatenate([np.ones((a3.shape[0], 1)), a3], axis=1)\n",
    "    \n",
    "    a4 = sigmoid(a3.dot(w3.T))\n",
    "    \n",
    "    y_matrix = y.reshape(-1)\n",
    "    y_matrix = np.eye(num_labels)[y_matrix]\n",
    "    \n",
    "    temp1 = w1\n",
    "    temp2 = w2\n",
    "    temp3 = w3\n",
    "    # Add regularization term\n",
    "    \n",
    "    reg_term = (lambda_ / (2 * m)) * (np.sum(np.square(temp1[:, 1:])) + np.sum(np.square(temp2[:, 1:])) + np.sum(np.square(temp3[:, 1:])))\n",
    "    \n",
    "    J = (-1 / m) * np.sum((np.log(a4) * y_matrix) + np.log(1 - a4) * (1 - y_matrix)) + reg_term\n",
    "  \n",
    "    # Backpropogation\n",
    "    delta_4= a4-y_matrix #Error of O/P layer\n",
    "    delta_3= delta_4.dot(w3)[:, 1:]*sigmoidGradient(a2.dot(w2.T))  #Error of hidden layer 2.\n",
    "    delta_2= delta_3.dot(w2)[:, 1:]*sigmoidGradient(a1.dot(w1.T))  #Error of hidden layer 1.\n",
    "    Delta1= delta_2.T.dot(a1)\n",
    "    Delta2= delta_3.T.dot(a2)\n",
    "    Delta3= delta_4.T.dot(a3)\n",
    "    \n",
    "    # Add regularization to gradient\n",
    "\n",
    "    \n",
    "    w1_grad= (1/m)*Delta1\n",
    "    w2_grad= (1/m)*Delta2\n",
    "    w3_grad= (1/m)*Delta3\n",
    "    \n",
    "    w1_grad[:, 1:]=  w1_grad[:, 1:] + (lambda_/m)*w1[:, 1:]\n",
    "    w2_grad[:, 1:]=  w2_grad[:, 1:] + (lambda_/m)*w2[:, 1:]\n",
    "    w3_grad[:, 1:]=  w3_grad[:, 1:] + (lambda_/m)*w3[:, 1:]\n",
    "    \n",
    "    grad= np.concatenate([w1_grad.ravel(), w2_grad.ravel(), w3_grad.ravel()]) \n",
    "    #=======================================================================================================\n",
    "   \n",
    "    \n",
    "   \n",
    "    return J,grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797fd2da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6fc10eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for single hidden layer\n",
    "\n",
    "# Write code to pass the cost function to scipy's optimise.minimize\n",
    "\n",
    "options= {'maxiter': 4000}\n",
    "\n",
    "\n",
    "lambda_ = 0.1\n",
    "\n",
    "\n",
    "costFunction_1 = lambda p: nnCostFunction_1(p, input_layer_size, # p == nn_param\n",
    "                                        hidden_layer_size_One,\n",
    "                                        num_labels, X_train, y_train, lambda_)\n",
    "\n",
    "res_1 = optimize.minimize(costFunction_1,\n",
    "                        initial_nn_params_1,\n",
    "                        jac=True,\n",
    "                        method='TNC',\n",
    "                        options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04226e98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     fun: 0.051366870584946794\n",
       "     jac: array([-3.73045991e-06, -5.98592710e-10,  1.93581103e-09, ...,\n",
       "       -4.39902546e-06, -7.92631566e-06, -9.53575926e-06])\n",
       " message: 'Max. number of function evaluations reached'\n",
       "    nfev: 4000\n",
       "     nit: 208\n",
       "  status: 3\n",
       " success: False\n",
       "       x: array([ 1.73729593e+00, -1.09557659e-03, -8.94366636e-03, ...,\n",
       "       -4.45191687e+00,  4.33263776e+00,  1.65157078e+00])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24fba0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for double hidden layers\n",
    "\n",
    "options= {'maxiter': 4000}\n",
    "\n",
    "\n",
    "lambda_ = 0.1\n",
    "\n",
    "\n",
    "costFunction_2 = lambda p: nnCostFunction_2(p, input_layer_size, # p == nn_param\n",
    "                                        hidden_layer_size_One,\n",
    "                                        hidden_layer_size_Two,\n",
    "                                        num_labels, X_train, y_train, lambda_)\n",
    "\n",
    "res_2 = optimize.minimize(costFunction_2,\n",
    "                        initial_nn_params_2,\n",
    "                        jac=True,\n",
    "                        method='TNC',\n",
    "                        options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee5db361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     fun: 0.024353527706477602\n",
       "     jac: array([ 4.23221875e-06, -5.50175969e-10,  9.02109110e-09, ...,\n",
       "        3.23519393e-06,  2.92366719e-06,  2.18376675e-06])\n",
       " message: 'Max. number of function evaluations reached'\n",
       "    nfev: 4000\n",
       "     nit: 256\n",
       "  status: 3\n",
       " success: False\n",
       "       x: array([-1.75573259e-01, -5.02476111e-05, -3.10517470e-03, ...,\n",
       "        6.97594206e-01,  6.66087848e-01,  9.05283597e-01])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8159d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in the test data at this point\n",
    "\n",
    "data_test= pd.read_csv('fashion-mnist_test.csv')\n",
    "X_test,y_test = data_clean_Display(data_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d8e10fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Break the nn_params into weights depending on how many layers you're using and \n",
    "#pass it to the predict function according to the number of layers you're using.\n",
    "\n",
    "## for single hidden layer\n",
    "\n",
    "nn_params_1 = res_1.x \n",
    "        \n",
    "# Obtained w1 and w2 back from nn_params\n",
    "w1_1 = np.reshape(nn_params_1[:hidden_layer_size_One * (input_layer_size + 1)],\n",
    "                        (hidden_layer_size_One, (input_layer_size + 1)))\n",
    "\n",
    "w2_1 = np.reshape(nn_params_1[(hidden_layer_size_One * (input_layer_size + 1)):],\n",
    "                        (num_labels, (hidden_layer_size_One + 1)))\n",
    "\n",
    "#check how the learned weights are performing on the test data.\n",
    "p_1 = predictSingleHiddenLayer(w1_1, w2_1, X_test)\n",
    "\n",
    "accuracy_1 = (np.mean(p_1 == y_test) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1afb057",
   "metadata": {},
   "outputs": [],
   "source": [
    "## for double hidden layers\n",
    "\n",
    "\n",
    "nn_params_2 = res_2.x \n",
    "        \n",
    "# Obtained w1, w2 and w3 back from nn_params\n",
    "w1_2 = np.reshape(nn_params_2[:hidden_layer_size_One * (input_layer_size + 1)],\n",
    "                        (hidden_layer_size_One, (input_layer_size + 1)))\n",
    "\n",
    "w2_2 = np.reshape(nn_params_2[(hidden_layer_size_One * (input_layer_size + 1)):hidden_layer_size_One * (input_layer_size + 1)+(hidden_layer_size_Two * (hidden_layer_size_One + 1))],\n",
    "                        (hidden_layer_size_Two, (hidden_layer_size_One + 1)))\n",
    "w3_2 = np.reshape(nn_params_2[(hidden_layer_size_One * (input_layer_size + 1)+(hidden_layer_size_Two * (hidden_layer_size_One + 1))):],\n",
    "                        (num_labels, (hidden_layer_size_Two + 1)))\n",
    "\n",
    "\n",
    "#check how the learned weights are performing on the test data.\n",
    "\n",
    "p_2 = predictDoubleHiddenLayer(w1_2, w2_2, w3_2, X_test)\n",
    "accuracy_2 = (np.mean(p_2 == y_test) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696be5e4",
   "metadata": {},
   "source": [
    "# 3. COMPARE the prediction efficiency of the NN from one hidden layer to double hidden layer >>>>>>for trainig and testing data respectively\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ecab9b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Accuracy for single hidden layer :  100.0\n",
      "Train Data Accuracy for double hidden layer :  100.0\n"
     ]
    }
   ],
   "source": [
    "p_train_1 = predictSingleHiddenLayer(w1_1, w2_1, X_train)\n",
    "p_train_2 = predictDoubleHiddenLayer(w1_2, w2_2,w3_2, X_train)\n",
    "print('Train Data Accuracy for single hidden layer : ',np.round(np.mean(p_train_1 == y_train) * 100,3))\n",
    "print('Train Data Accuracy for double hidden layer : ',np.round(np.mean(p_train_2 == y_train) * 100,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e62c1f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data Accuracy for single hidden layer :  90.0\n",
      "Test Data Accuracy for double hidden layer :  86.667\n"
     ]
    }
   ],
   "source": [
    "p_1 = predictSingleHiddenLayer(w1_1, w2_1, X_test)\n",
    "accuracy_1 = (np.mean(p_1 == y_test) * 100)\n",
    "\n",
    "p_2 = predictDoubleHiddenLayer(w1_2, w2_2, w3_2, X_test)\n",
    "accuracy_2 = (np.mean(p_2 == y_test) * 100)\n",
    "\n",
    "print('Test Data Accuracy for single hidden layer : ',np.round(accuracy_1,3))\n",
    "print('Test Data Accuracy for double hidden layer : ',np.round(accuracy_2,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca91c1f",
   "metadata": {},
   "source": [
    "# 4. Use the test data to plot few images along with the model predicted labels/classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "047b7b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dress         Shirt         Ankle boots         "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "m = y_test.size\n",
    "# Randomly selected 49 data points to display\n",
    "rand_indices = np.random.choice(m, 3, replace=False)\n",
    "\n",
    "for i in rand_indices:\n",
    "   print(label_dict[y_test[i]], end='         ')\n",
    "sel = X_test[rand_indices, :]\n",
    "displayData(sel)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb6a53a",
   "metadata": {},
   "source": [
    "# 5. Compare how the two NNs fare in terms of prediction accuracy for the same number of optimisation iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70dfaf61",
   "metadata": {},
   "source": [
    "Theoretically speaking there will be more accuracy with incrament in \n",
    "the number of layers and the number of nodes in a particular layer. \n",
    "So, since two hidden layers will have more number of layers so it should \n",
    "be more accurate but will become more complex for computions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b256096",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
